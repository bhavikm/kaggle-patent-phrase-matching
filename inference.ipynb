{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "iskaggle = os.environ.get('KAGGLE_KERNEL_RUN_TYPE', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if iskaggle:\n",
    "    pip install datasets --find-links /kaggle/input/us-patent-phrase-to-phrase-matching/frozen_packages --no-index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "from sklearn.model_selection import train_test_split\n",
    "import random\n",
    "import os\n",
    "import torch\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "import shutil\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import AutoModel, AutoConfig, AutoTokenizer, get_linear_schedule_with_warmup, TrainingArguments, Trainer, AutoModelForSequenceClassification\n",
    "from datasets import load_metric\n",
    "import datasets\n",
    "from transformers import BertModel\n",
    "import torch.nn as nn\n",
    "from torch.optim import Adam\n",
    "from tqdm import tqdm\n",
    "import warnings, transformers, logging, torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
    "warnings.simplefilter('ignore')\n",
    "logging.disable(logging.WARNING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CFG:\n",
    "    if iskaggle:\n",
    "        input_path = '../input/us-patent-phrase-to-phrase-matching'\n",
    "    else:\n",
    "        input_path = '/home/bhavik/projects/kaggle-patent-phrase-matching/data'\n",
    "    model_path = 'anferico/bert-for-patents'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if iskaggle:\n",
    "    titles = pd.read_csv(f\"../input/us-patents-category-titles/titles.csv\")\n",
    "else:\n",
    "    titles = pd.read_csv(f\"{CFG.input_path}/titles.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_input_tokens(df):\n",
    "    return df['title'] + ' ' + df['anchor']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv(f\"{CFG.input_path}/test.csv\")\n",
    "test_df = test_df.merge(titles, left_on='context', right_on='code')\n",
    "test_df['input'] = prep_input_tokens(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('uspppm_0')\n",
    "\n",
    "class InferDataset(Dataset):\n",
    "    def __init__(self, df):\n",
    "        self.inputs = df['input'].values.astype(str)\n",
    "        self.targets = df['target'].values.astype(str)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.inputs)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        inputs = self.inputs[item]\n",
    "        targets = self.targets[item]\n",
    "        \n",
    "        return {\n",
    "        **tokenizer( inputs, targets )\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "test_predictions = []\n",
    "\n",
    "for fold in range(CFG.num_fold):\n",
    "\n",
    "    test_dataset = InferDataset(test_df)\n",
    "    test_outputs = trainer.predict(test_dataset)\n",
    "    test_prediction = test_outputs.predictions.reshape(-1)\n",
    "    test_predictions.append(test_prediction)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predictions = np.mean(test_predictions, axis=0)\n",
    "submission = datasets.Dataset.from_dict({\n",
    "    'id': test_df['id'],\n",
    "    'score': test_predictions,\n",
    "})\n",
    "\n",
    "submission.to_csv('submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
